---
title: "Assignment 6: GLMs (Linear Regressios, ANOVA, & t-tests)"
author: "GuruBandaa Khalsa"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# This code chunk will tidy your knit PDF files, wrapping long code lines
# For it to work, the "formatR" package needs to be installed

# install.packages('formatR')
library('formatR')
library('lubridate')
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy=TRUE)
```

## OVERVIEW

This exercise accompanies the lessons in Environmental Data Analytics on generalized linear models. 

## Directions
1. Rename this file `<FirstLast>_A06_GLMs.Rmd` (replacing `<FirstLast>` with your first and last name).
2. Change "Student Name" on line 3 (above) with your name.
3. Work through the steps, **creating code and output** that fulfill each instruction.
4. Be sure to **answer the questions** in this assignment document.
5. When you have completed the assignment, **Knit** the text and code into a single PDF file.


## Set up your session 
1. Set up your session. Check your working directory. Load the tidyverse, agricolae and other needed packages. Import the *raw* NTL-LTER raw data file for chemistry/physics (`NTL-LTER_Lake_ChemistryPhysics_Raw.csv`). Set date columns to date objects.

2. Build a ggplot theme and set it as your default theme.

```{r setup 2}
#1. I checked my working directory using the getwd() function, loaded the
# `tidyverse' and `agricolae' packages, and imported the raw NTL-LTER raw data
# file for chemistry/physics.  I also set date columns to date objects.
getwd()
library(tidyverse)
library(agricolae)
NTL1 <- read.csv("~/Desktop/Masters at Duke/Second Year/Fall Semester/Environmental Data Analytics/EDA-Fall2022/Data/Raw/NTL-LTER_Lake_ChemistryPhysics_Raw.csv")
View(NTL1)
NTL1$sampledate <- as.Date(NTL1$sampledate, format = "%m/%d/%y")

#2. I assigned a pre-built theme from Ggplot as a common theme across all plots
#   in my analysis session.
mytheme <- theme_classic(base_size = 14) +
  theme(axis.text = element_text(color = "black"), 
        legend.position = "top")

```

## Simple regression
Our first research question is: Does mean lake temperature recorded during July change with depth across all lakes?

3. State the null and alternative hypotheses for this question:
> Answer:
H0: Mean lake temperature recorded during July has an effect on depth across
    all lakes.
Ha: Mean lake temperature recorded during July has no effect on depth across
    all lakes.


4.  Wrangle your NTL-LTER dataset with a pipe function so that the records meet the following criteria: 
 * Only dates in July. 
 * Only the columns: `lakename`, `year4`, `daynum`, `depth`, `temperature_C`
 * Only complete cases (i.e., remove NAs)

5. Visualize the relationship among the two continuous variables with a scatter plot of temperature by depth. Add a smoothed line showing the linear model, and limit temperature values from 0 to 35 °C. Make this plot look pretty and easy to read.

```{r scatterplot}
#4. I wrangled the NTL-LTER dataset with a pipe function so that the records
#   follow the criteria listed above.
NTL1.wrangle <-
  NTL1 %>%
  mutate(month = month(sampledate), year = year(sampledate))%>%
  filter(month == "7") %>%
  select(lakename, year4, daynum, depth, temperature_C) %>%
  drop_na()

#5. I visualized the relationship among the two continuous variables with a
#   scatter plot of temperature by depth with a smoothed line showing the
#   linear model.  I also limited values from 0 to 35 °C.
NTL1.wrangle.plot <-
  ggplot(NTL1.wrangle, aes(x = depth, y = temperature_C)) +
  geom_point(aes(color = temperature_C), alpha = 0.3) +
  geom_smooth(method = "lm", col = "blue") +
  xlim(0, 20) +
  ylim(0, 35) +
  xlab("Temperature (°Celsius)") +
  ylab("Depth (meters)")
print(NTL1.wrangle.plot)

```


6. Interpret the figure. What does it suggest with regards to the response of temperature to depth? Do the distribution of points suggest about anything about the linearity of this trend?

> Answer: The figure suggests that temperature decreases with depth.
          The distribution of the points suggests that the relationship is most
          linear in the temperature range of 4 to 8°C.  The trend levels  out
          once 8°C is approached.


7. Perform a linear regression to test the relationship and display the results

```{r linear.regression}
#7. I performed a linear regression to test the relationship and displayed the
#   results.  The p-value is less than 2.2e-16, or in other words, it is
#   statistically significant.
NTL1.wrangle.regression <- lm(data = NTL1.wrangle,  temperature_C ~ depth)
summary(NTL1.wrangle.regression)

```


8. Interpret your model results in words. Include how much of the variability in temperature is explained by changes in depth, the degrees of freedom on which this finding is based, and the statistical significance of the result. Also mention how much temperature is predicted to change for every 1m change in depth. 

> Answer: 73.9% of the variability in temperature is explained by changes in
          depth.  This finding is based on the 9,726 degrees of freedom.  The
          result shows a statistical significance of less than 2.2e-16.
          This means that we reject our null hypothesis that mean lake
          temperature recorded during July has no effect on depth across all
          lakes.  This means that depth does have an effect on mean temperature
          of lakes.  For every 1 meter change in depth, temperature is
          predicted to decrease by 1.95 degrees Celsius.


---

## Multiple regression
Let's tackle a similar question from a different approach. Here, we want to explore what might the best set of predictors for lake temperature in July across the monitoring period at the North Temperate Lakes LTER. 


9. Run an AIC to determine what set of explanatory variables (year4, daynum, depth) is best suited to predict temperature.

10. Run a multiple regression on the recommended set of variables. 

```{r temperature.model}
#9. I ran an AIC to determine what set of explanatory variables is best suited
#   to predict temperature.
NTL1.wrangle.ALLregression <- lm(data = NTL1.wrangle, temperature_C ~ depth + year4 + daynum)
summary(NTL1.wrangle.ALLregression)
step(NTL1.wrangle.ALLregression)


#10. I ran a multiple regression on the recommended set of variables.
# I removed year4, since it would improve the AIC
NTL1.wrangle.BESTregression <- lm(data = NTL1.wrangle, temperature_C ~ depth + daynum)
summary(NTL1.wrangle.BESTregression)
step(NTL1.wrangle.BESTregression)

par(mfrow = c(2,2), mar=c(4,4,4,4))
plot(NTL1.wrangle.ALLregression)
par(mfrow = c(1,1))
summary(NTL1.wrangle.ALLregression)

```

11. What is the final set of explanatory variables that the AIC method suggests we use to predict temperature in our multiple regression? How much of the observed variance does this model explain? Is this an improvement over the model using only depth as the explanatory variable?

> Answer: The final set of explanatory variables that the AIC method suggests
          we use to predict temperature in our multiple regression includes
          only the relationship between temperature and depth as well as
          "daynum."  The observed variance is 74.1% of the variance in
          temperature.  This is an improvement from 73.9% when only
          depth was included.



---
## Analysis of Variance

12. Now we want to see whether the different lakes have, on average, different temperatures in the month of July. Run an ANOVA test to complete this analysis. (No need to test assumptions of normality or similar variances.) Create two sets of models: one expressed as an ANOVA models and another expressed as a linear model (as done in our lessons).

```{r anova.model}
#12. I created an ANOVA model and a linear model to see whether the different
#    lakes have, on average, different temperatures in the month of July.

# ANOVA Model
NTL1.wrangle.anova <- aov(data = NTL1.wrangle, temperature_C ~ lakename)
summary(NTL1.wrangle.anova)

par(mfrow = c(2,2), mar=c(4,4,4,4))
plot(NTL1.wrangle.anova)
par(mfrow = c(1,1))

# Linear Model
NTL1.wrangle.anova2 <- lm(data = NTL1.wrangle, temperature_C ~ lakename)
summary(NTL1.wrangle.anova2)

par(mfrow = c(2,2), mar=c(4,4,4,4))
plot(NTL1.wrangle.anova2)
par(mfrow = c(1,1))

```

13. Is there a significant difference in mean temperature among the lakes? Report your findings. 

> Answer: There is not a significant difference in mean temperature among the
          lakes.  The ANOVA model found that the difference between the pair of
          group means is statistically significant, so we reject the null
          hypothesis.  The p-value for our AOC model is less than 0.05, so we
          reject our null hypothesis that both lakes have the same mean
          temperature.



14. Create a graph that depicts temperature by depth, with a separate color for each lake. Add a geom_smooth (method = "lm", se = FALSE) for each lake. Make your points 50 % transparent. Adjust your y axis limits to go from 0 to 35 degrees. Clean up your graph to make it pretty. 

```{r scatterplot.2}
#14. I created a graph that depicts temperature by depth, with a separate color
#    for each lake with a geom_smooth for each lake.
NTL1.wrangle.plot <-
  ggplot(NTL1.wrangle, aes(x = depth, y = temperature_C)) +
  geom_point(aes(color = lakename), alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, col = "blue") +
  xlim(0, 20) +
  ylim(0, 35) +
  xlab("Temperature (°Celsius)") +
  ylab("Depth (meters)")
print(NTL1.wrangle.plot)

```

15. Use the Tukey's HSD test to determine which lakes have different means.

```{r tukey.test}
#15. I used the Tukey's HSD test to determine which lakes have different means.
TukeyHSD(NTL1.wrangle.anova)

```

16.From the findings above, which lakes have the same mean temperature, statistically speaking, as Peter Lake? Does any lake have a mean temperature that is statistically distinct from all the other lakes?

>Answer: From the findings above, Peter Lake and Ward Lake have the same mean
         temperature, statistically speaking, as Peter Lake. The p-values given
         from the Tukey HSD test are all above 0.05 for their relationship with
         Peter Lake.  Central Long Lake is statistically distinct from all the
         other lakes.

 

17. If we were just looking at Peter Lake and Paul Lake. What's another test we might explore to see whether they have distinct mean temperatures? 

>Answer: If we were just looking at Peter Lake and Paul Lake, we might explore
         the two-way Bartlett to see whether they have distinct mean
         tempeatures.



18. Wrangle the July data to include only records for Crampton Lake and Ward Lake. Run the two-sample T-test on these data to determine whether their July temperature are same or different. What does the test say? Are the mean temperatures for the lakes equal? Does that match you answer for part 16?

```{r t.test}
#18. I wrangled the July data to include only records for Crampton Lake and
#    Ward Lake.
NTL1.wrangle2 <-
  NTL1.wrangle %>%
  filter(lakename == "Crampton Lake" | lakename == "Ward Lake")

View(NTL1.wrangle2)

# I then ran the two-sample T-test.
t.test(data = NTL1.wrangle2, temperature_C ~ lakename)

```

>Answer: The test says that the p-value is not significant (>0.05), therefore
         the July temperatures of Crampton Lake and Ward Lake are different.
         We reject our null hypothesis that they are the same.  When looking
         back at the Tukey HSD test, the relationship between Crampton Lake and
         Ward Lake has a p-value of 0.97, therefore we rejected the null
         hypothesis that the two mean temperatures are the same.  We determine
         that the mean temperatures in this t-test are the same means reported
         in the Tukey HSD test from part 16.
